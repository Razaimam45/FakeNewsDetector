{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd057baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 92.9%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[592,  46],\n",
       "       [ 44, 585]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "#Fake News Detection Using Machine Learning\n",
    "\n",
    "#Fake News - A type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false and/or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#train_test_split - split arrays or matrices into random train and test subsets\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#TF (Term Frequency): The number of times a word appears in a document is its Term Frequency\n",
    "\n",
    "#IDF (Inverse Document Frequency): Words that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.\n",
    "\n",
    "#TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "#Passive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#reading the data\n",
    "df = pd.read_csv('news.csv')\n",
    "\n",
    "#getting shape and head\n",
    "df.shape\n",
    "df.head()\n",
    "\n",
    "#getting the labels\n",
    "labels=df.label\n",
    "labels.head()\n",
    "\n",
    "#Train/Test is a method to measure the accuracy of the model. It is called Train/Test because you split the the data set into two sets: a TRAINING set and a TESTING set. 80% for training, and 20% for testing. You train the model using the training set. You test the model using the testing set.\n",
    "\n",
    "#Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], labels, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "#Stop words are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc. Such words are already captured this in corpus named corpus.\n",
    "\n",
    "#intializing a TfidVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "#fit and transform train set, transform test set\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "#initializing a passiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "#Predicting on the test set and calculating accuracy\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "\n",
    "#A true positive is an outcome where the model correctly predicts the positive class. Similarly, a true negative is an outcome where the model correctly predicts the negative class. A false positive is an outcome where the model incorrectly predicts the positive class.\n",
    "\n",
    "confusion_matrix(y_test, y_pred, labels=['FAKE', 'REAL'])"
   ]
  }
 ]
}